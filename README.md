# This warehouse offers source code and datasets for the ADEB-NET, the paper title entitled: Multivariable high-dimension time-series prediction in SIoT via adaptive dual-graph-attention encoder-decoder with global Bayesian optimization.
Abstract: In the current intelligent era, data is continuously recorded from various data sources and devices, resulting in a High-dimensional Multivariate Time-Series (HMTS). The Social Internet of Things (SIoT) is an emerging paradigm that emphasizes the importance of time-series forecasting, which plays a crucial role in facilitating intelligent decision-making. However, existing time-series predictors often ignore the variable structural correlation inherent in practical time-series data. Therefore, this study proposes an adaptive Encoder-decoder forecasting framework (ADEB-Net) to explore internal event information and topology relationship among varying variables. Specifically, the dual graphic attention mechanism is initially introduced to represent the spatiotemporal characteristics and dimensional relationships among complex variable structures. Subsequently, an adaptive encoder-decoder architecture with global Bayesian optimization is designed to complete dynamic temporal prediction troubled by multi-factor information conflict and dimensional disaster. Extensive experiments on three SIoT datasets demonstrated the outstanding performance of proposed framework surpassing state-of-the-art predictors. Further ablation analysis verified the ADEB-Net obtains a preferable balance between performance and efficiency, which exhibits application prospect in terms of intelligent SIoT systems.
# The roles of the six python program files are as follows:
  (1) main.py: main program, scheduling training, Bayesian optimization count setting. Run this program to start the ADE-BGI.<br>(2) layers.py: covers each neural network module and layer of the ADE-BGI, including the DRM and the AEFM.<br>(3) networks.py: the transmission of layers of the neural network.<br>(4) neural_trainer.py: the training, validation and testing process of the neural network.<br>(5) ParameterSet.py: parameter setting.<br>(6) losses.py: contains loss functions and evaluation metrics. 　
# The description of each dataset in the data folder is as follows:
  (1) Constituent Shares of the Shanghai Stock Exchange 50 Dataset (CSSSED)<br>  The CSSSED describes how the four price variables of the Constituent Shares of the Shanghai Stock Exchange 50 (000016) change over time. The dataset uses the 50 constituent stocks when the stock opens from May 2022 to August 2022, with 84-time steps, and the variables include opening price, closing price, highest price, and lowest price. The 50 constituent stocks are subject to the August 31, 2022, announcement by Eastmoney.com (https://www.eastmoney.com/). Since the constituent stocks of SSE 50 are adjusted every six months (January and July each year), the short-term prices of constituent stocks are more meaningful. The three-dimensional state of data can be expressed as (50, 84, 4). The total data volume (i.e., s×t×v) is 16800.<br>(2) Chinese Urban Air Quality Dataset (CUAQD)<br>  The CUAQD describes in 100 cities in China in the first 21 days of March 2022, three variables including AQI, PM2.5, and PM2.5 24-hour moving average change over time. With 504-time points, the sampling frequency is 1 hour. There is a small number of missing values, and the KNN algorithm (K=3) is used for interpolation. The three-dimensional state of data can be expressed as (100, 504, 3). The total data volume is 151200.<br>(3) PEMS-08<br>  The PEMS-08 describes traffic conditions detected by detectors deployed on highways in major metropolitan areas of California, USA. It has 170 detectors, the time is from July to August 2016 and the sampling frequency is 5 minutes (i.e., there are 17856-time points), considering three traffic measurements, namely total flow, average speed, and average occupancy. We used a subset of it in the main experiment, taking the amount of data from the previous four weeks(i.e., 8064-time points). The three-dimensional state of data can be expressed as (170, 8064, 3). The total data volume is 4112640.
